数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。那如何来衡量你编写的算法代码的执行效率呢？这里就要用到我们今天要讲的内容：时间、空间复杂度分析。

#### 为什么需要复杂度分析？

首先，我可以肯定地说，你这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给这种方法起了一个名字，叫事后统计法。但是，这种统计方法有非常大的局限性。

- 1. 测试结果非常依赖测试环境

测试环境中硬件的不同会对测试结果有很大的影响。比如，我们拿同样一段代码，分别用 Intel Core i9 处理器和 Intel Core i3 处理器来运行，不用说，i9 处理器要比 i3 处理器执行的速度快很多。还有，比如原本在这台机器上 a 代码执行的速度比 b 代码要快，等我们换到另一台机器上时，可能会有截然相反的结果。

- 2. 测试结果受数据规模的影响很大

后面我们会讲排序算法，我们先拿它举个例子。对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别。极端情况下，如果数据已经是有序的，那排序算法不需要做任何操作，执行时间就会非常短。除此之外，如果测试数据规模太小，测试结果可能无法真实地反应算法的性能。比如，对于小规模的数据排序，插入排序可能反倒会比快速排序要快！

所以，我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法。这就是我们今天要讲的时间、空间复杂度分析方法。

#### 大 O 复杂度表示法

算法的执行效率，粗略地讲，就是算法代码执行的时间

这里有段非常简单的代码，求 1,2,3…n 的累加和。现在，我就带你一块来估算一下这段代码的执行时间。
```
1function cal(n) {
2   var sum = 0;
3   var i = 1;
4   for (; i <= n; ++i) {
5     sum = sum + i;
6   }
7   return sum;
8 }
```


从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。在这个假设的基础之上，这段代码的总执行时间是多少呢？

第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n*unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)*unit_time。可以看出来，所有代码的执行时间 T(n) 与每行代码的执行次数成正比。

按照这个分析思路，我们再来看这段代码。

```
1funtion cal(n) {
2   var sum = 0;
3   var i = 1;
4   var  j = 1;
5    for (; i <= n; ++i) {
6     j = 1;
7     for (; j <= n; ++j) {
8       sum = sum +  i * j;
9     }
10   }
11}
```
我们依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？

第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间，第 5、6 行代码循环执行了 n 遍，需要 2n * unit_time 的执行时间，第 7、8 行代码循环执行了 n2遍，所以需要 2n2 * unit_time 的执行时间。所以，整段代码总的执行时间 


```
T(n) = (2n2+2n+3)*unit_time。
```


尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律:

> 所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比


```
T(n) = O((f(n))
```
我来具体解释一下这个公式。其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。

> 所以，第一个例子中的 T(n) = O(2n+2)，第二个例子中的 T(n) = O(2n2+2n+3)。这就是大 O 时间复杂度表示法。大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：


```
T(n) = O(n)； T(n) = O(n2)。
```
推导的过程


```
T(n) = (2n+2)*unit_time -> T(n) = O(2n+2) -> T(n) = O(n)
T(n) = (2n2+2n+3)*unit_time => T(n) = O(2n2+2n+3) -> T(n) = O(n2)

```


#### 时间复杂度分析

如何分析一段代码的时间复杂度？三个比较实用的方法

1. 只关注循环执行次数最多的的一段代码
    大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。
    ```
    1function cal(n) {
    2   var sum = 0;
    3   var i = 1;
    4   for (; i <= n; ++i) {
    5     sum = sum + i;
    6   }
    7   return sum;
    8 }
    ```
    2.3代码都是常量级别的执行时间，与n的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是滴4、5行代码，所以这块代码要重点分析。那两行代码执行了n次，所以总的时间复杂度就是O(n)
    
    
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度

    综合这三段代码的时间复杂度(分别是O(1), O(n), O(n2))，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n2)。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是：

    如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).
    
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
    类似嵌套循环的，都是用乘法来处理
### 大O
- O(1),O(n),O(nlogn),O(nlogn),O(n^2)
- 大O描述的是算法的运行时间和输入数据之间的关系

O(n)是nums中的元素个数算法和n呈线性关系，忽略了常数。实际是
```
T = c1*n + c2;
但是
T = 2*n + 2 O(n)
T = 2000*n + 10000 O(n)
T = 1*n*n + 0 O(n^2)

上面的表达式中第三个n下于3000的时候都是比前面的要小的，但是在n接近无穷的时候，
就是不一样了，所以O是渐进时间复杂度描述n趋近于无穷的情况

```

- O一般是计算最坏的结果
- 均摊复杂度，有时早规律出现的时候可以使用均摊复杂度
- 复杂度震荡，在边界情况下，来回操作，过于着急（Eager)解决方案就是Lazy

![Big O graphs](https://zky.koocdn.com/club/picture/8d5d86ecb45043edb99825cebccd5632.png)

源: [Big O Cheat Sheet](http://bigocheatsheet.com/).

以下是一些最常用的 大O标记法 列表以及它们与不同大小输入数据的性能比较。

| 大O标记法      | 计算10个元素                 | 计算100个元素                 | 计算1000个元素                  |
| -------------- | ---------------------------- | ----------------------------- | ------------------------------- |
| **O(1)**       | 1                            | 1                             | 1                               |
| **O(log N)**   | 3                            | 6                             | 9                               |
| **O(N)**       | 10                           | 100                           | 1000                            |
| **O(N log N)** | 30                           | 600                           | 9000                            |
| **O(N^2)**     | 100                          | 10000                         | 1000000                         |
| **O(2^N)**     | 1024                         | 1.26e+29                      | 1.07e+301                       |
| **O(N!)**      | 3628800                      | 9.3e+157                      | 4.02e+2567                      |


#### **O(log N)**和**O(N log N)**分析

对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。

```
i=1;
while (i <= n)  {
     i = i * 2;
}
```
根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：

```
20  21   22  ... 2k ... 2n = n
2的0次方
```
所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2x=n 求解 x 这个问题我们想高中应该就学过了，我就不多说了。x=log2n，所以，这段代码的时间复杂度就是 O(log2n)

如果换成i= i * 3 就是O(log3n)

实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？

我们知道，对数之间是可以互相转换的，log3n 就等于 log32 * log2n，所以 O(log3n) = O(C * log2n)，其中 C=log32 是一个常量。基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。所以，O(log2n) 就等于 O(log3n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)。

如果你理解了我前面讲的 O(logn)，那 O(nlogn) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了。而且，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。

#### O(m+n) 、O(m*n)

我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定。老规矩，先看代码！

```
function cal(m, n) {
  var sum_1 = 0;
  var i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }
  var sum_2 = 0;
  var j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }
  return sum_1 + sum_2;
}
```
从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。


### 数据结构操作的复杂性

| 数据结构                | 连接      | 查找      | 插入      | 删除      |
| ----------------------- | :-------: | :-------: | :-------: | :-------: |
| **数组**                | 1         | n         | n         | n         |
| **栈**                  | n         | n         | 1         | 1         |
| **队列**                | n         | n         | 1         | 1         |
| **链表**                | n         | n         | 1         | 1         |
| **哈希表**              | -         | n         | n         | n         |
| **二分查找树**          | n         | n         | n         | n         |
| **B树**                 | log(n)    | log(n)    | log(n)    | log(n)    |
| **红黑树**              | log(n)    | log(n)    | log(n)    | log(n)    |
| **AVL树**               | log(n)    | log(n)    | log(n)    | log(n)    |

### 数组排序算法的复杂性

| 名称                  | 最优      | 平均      | 最坏          | 内存      | 稳定      |
| --------------------- | :-------: | :-------: | :-----------: | :-------: | :-------: |
| **冒泡排序**          | n         | n^2       | n^2           | 1         | Yes       |
| **插入排序**          | n         | n^2       | n^2           | 1         | Yes       |
| **选择排序**          | n^2       | n^2       | n^2           | 1         | No        |
| **堆排序**            | n log(n)  | n log(n)  | n log(n)      | 1         | No        |
| **归并排序**          | n log(n)  | n log(n)  | n log(n)      | n         | Yes       |
| **快速排序**          | n log(n)  | n log(n)  | n^2           | log(n)    | No        |
| **希尔排序**          | n log(n)  | 取决于差距序列   | n (log(n))^2  | 1         | No        |


## 空间复杂度分析

前面，咱们花了很长时间讲大 O 表示法和时间复杂度分析，理解了前面讲的内容，空间复杂度分析方法学起来就非常简单了。

前面我讲过，时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。

我还是拿具体的例子来给你说明。（这段代